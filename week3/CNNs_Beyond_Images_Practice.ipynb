{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f6b35c3",
   "metadata": {},
   "source": [
    "\n",
    "# Convolutions Beyond Images: 1D CNNs, Causality, Audio, and Text\n",
    "\n",
    "Hands-on notebook aligned with the lecture \"Convolutions beyond images\".\n",
    "You will:\n",
    "- Implement and visualize 1D convolutions, causal masks, and dilations.\n",
    "- Build a tiny autoregressive forecaster on a synthetic time series.\n",
    "- Generate simple spectrogram features and run a toy CNN over them.\n",
    "- Practice padding variable-length sequences for batching.\n",
    "- Explore basic tokenization and embeddings, with NumPy-first examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dadc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(suppress=True, linewidth=120)\n",
    "def seed_all(seed=0):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_all(7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610f9739",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1 — 1D Convolutions on Sequences\n",
    "\n",
    "We represent a length-$n$ sequence with $c$ channels as a matrix $X \\in \\mathbb{R}^{n \\times c}$.\n",
    "A 1D convolution extracts local patches and applies a learned kernel to each patch:\n",
    "$$\n",
    "H[i] = \\phi\\big( W \\cdot \\mathrm{vec}(\\text{patch around } i) + b \\big).\n",
    "$$\n",
    "\n",
    "We will implement a simple **valid** convolution for clarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b844251",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv1d_valid(X, K):\n",
    "    \"\"\"\n",
    "    X: (n, c) sequence\n",
    "    K: (s, c, c_out) kernel, s = kernel size, c_in = c\n",
    "    Returns H: (n - s + 1, c_out)\n",
    "    \"\"\"\n",
    "    n, c = X.shape\n",
    "    s, c_in, c_out = K.shape\n",
    "    assert c_in == c\n",
    "    H = np.zeros((n - s + 1, c_out), dtype=X.dtype)\n",
    "    for i in range(n - s + 1):\n",
    "        patch = X[i:i+s, :]  # (s, c)\n",
    "        # vectorized filter application: sum over s and c\n",
    "        # output shape (c_out,)\n",
    "        H[i] = np.tensordot(patch, K, axes=([0,1],[0,1]))\n",
    "    return H\n",
    "\n",
    "# quick demo\n",
    "seed_all(0)\n",
    "n, c, s, c_out = 16, 2, 3, 4\n",
    "X = np.random.randn(n, c)\n",
    "K = np.random.randn(s, c, c_out) * 0.1\n",
    "H = conv1d_valid(X, K)\n",
    "H.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba46d95",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2 — Causal (Masked) Convolutions\n",
    "\n",
    "For forecasting, ensure output at time $i$ depends only on inputs $\\le i$.\n",
    "We enforce **causality** by padding on the left and not using future positions.\n",
    "Implementation trick: left-pad with $(s-1)$ zeros, then do a valid convolution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f78efe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv1d_causal(X, K):\n",
    "    \"\"\"\n",
    "    Causal 1D conv with left padding of size (s-1).\n",
    "    X: (n, c)\n",
    "    K: (s, c, c_out)\n",
    "    Returns H: (n, c_out), aligned with X positions 0..n-1.\n",
    "    \"\"\"\n",
    "    s = K.shape[0]\n",
    "    pad = np.zeros((s-1, X.shape[1]), dtype=X.dtype)\n",
    "    X_pad = np.concatenate([pad, X], axis=0)  # (n + s - 1, c)\n",
    "    H_valid = conv1d_valid(X_pad, K)          # (n, c_out)\n",
    "    return H_valid\n",
    "\n",
    "# sanity check shapes\n",
    "Hc = conv1d_causal(X, K)\n",
    "H.shape, Hc.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e5ad7b",
   "metadata": {},
   "source": [
    "\n",
    "## Part 3 — Dilated Convolutions\n",
    "\n",
    "A **dilated** kernel samples inputs with a stride $d$ inside the receptive field,\n",
    "increasing receptive field without increasing parameter count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a769e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv1d_dilated_causal(X, K, dilation=1):\n",
    "    \"\"\"\n",
    "    Dilated causal 1D conv via left padding.\n",
    "    For kernel size s and dilation d, the receptive field width is (s-1)*d + 1.\n",
    "    X: (n, c), K: (s, c, c_out)\n",
    "    Returns (n, c_out)\n",
    "    \"\"\"\n",
    "    s = K.shape[0]\n",
    "    # effective width\n",
    "    width = (s - 1) * dilation + 1\n",
    "    pad = np.zeros((width - 1, X.shape[1]), dtype=X.dtype)\n",
    "    X_pad = np.concatenate([pad, X], axis=0)  # (n + width - 1, c)\n",
    "    n = X.shape[0]\n",
    "    c_out = K.shape[2]\n",
    "    H = np.zeros((n, c_out), dtype=X.dtype)\n",
    "    for i in range(n):\n",
    "        # gather dilated patch ending at i\n",
    "        idxs = [i + width - 1 - j*dilation for j in range(s)]\n",
    "        # reverse order so kernel K[0] aligns with oldest element\n",
    "        idxs = idxs[::-1]\n",
    "        patch = X_pad[idxs, :]  # (s, c)\n",
    "        H[i] = np.tensordot(patch, K, axes=([0,1],[0,1]))\n",
    "    return H\n",
    "\n",
    "# visualize dilation growth of receptive field by plotting outputs\n",
    "seed_all(1)\n",
    "X_demo = np.zeros((40,1)); X_demo[10] = 1.0  # impulse\n",
    "K_demo = np.ones((3,1,1))\n",
    "H_d1 = conv1d_dilated_causal(X_demo, K_demo, dilation=1)\n",
    "H_d2 = conv1d_dilated_causal(X_demo, K_demo, dilation=2)\n",
    "H_d4 = conv1d_dilated_causal(X_demo, K_demo, dilation=4)\n",
    "\n",
    "plt.figure(figsize=(9,3))\n",
    "plt.plot(H_d1[:,0], label=\"d=1\")\n",
    "plt.plot(H_d2[:,0], label=\"d=2\")\n",
    "plt.plot(H_d4[:,0], label=\"d=4\")\n",
    "plt.title(\"Dilated causal conv outputs for an impulse input\")\n",
    "plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c97032",
   "metadata": {},
   "source": [
    "\n",
    "## Part 4 — Forecasting with a Causal CNN\n",
    "\n",
    "We build a synthetic time series and train a tiny causal CNN to predict the next value at each step.\n",
    "Loss: mean squared error between predicted next-step $\\hat{x}_{t+1}$ and true $x_{t+1}$.\n",
    "This is a teacher-forcing setup for one-step prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_series(T=400, noise=0.05):\n",
    "    t = np.linspace(0, 8*np.pi, T)\n",
    "    x = np.sin(t) + 0.3*np.sin(3*t + 0.5) + noise*np.random.randn(T)\n",
    "    return x\n",
    "\n",
    "def make_dataset_1d(x, s, horizon=1):\n",
    "    \"\"\"\n",
    "    Build supervised pairs (patch->next value) for a single-channel series.\n",
    "    Returns X: (N, s, 1), Y: (N, 1)\n",
    "    \"\"\"\n",
    "    N = len(x) - s - horizon + 1\n",
    "    X = np.zeros((N, s, 1))\n",
    "    Y = np.zeros((N, 1))\n",
    "    for i in range(N):\n",
    "        X[i,:,0] = x[i:i+s]\n",
    "        Y[i,0]  = x[i+s]  # next-step target\n",
    "    return X, Y\n",
    "\n",
    "seed_all(3)\n",
    "x = make_series(T=600, noise=0.03)\n",
    "s = 9           # kernel size / receptive field window\n",
    "X_sup, Y_sup = make_dataset_1d(x, s=s)\n",
    "\n",
    "# simple 1-layer causal conv regressor: y_hat = X * K + b, applied at last time step only\n",
    "K_reg = np.random.randn(s, 1, 1)*0.1\n",
    "b_reg = np.zeros((1,))\n",
    "\n",
    "def predict_batch(Xb, K, b):\n",
    "    # apply 1D conv causally then take last output as prediction\n",
    "    # Here equivalently: weighted sum over the s-window\n",
    "    # Using conv definition: H[i] = sum_{u,c} X[i+u,c]*K[u,c]\n",
    "    # since Xb windows are aligned, we directly tensordot\n",
    "    return np.tensordot(Xb, K, axes=([1,2],[0,1])).reshape(-1,1) + b  # (N,1)\n",
    "\n",
    "def mse(a, b):\n",
    "    return np.mean((a-b)**2)\n",
    "\n",
    "lr = 1e-2\n",
    "for epoch in range(200):\n",
    "    # mini-batch SGD over random slices\n",
    "    idx = np.random.randint(0, X_sup.shape[0], size=64)\n",
    "    Xb, Yb = X_sup[idx], Y_sup[idx]\n",
    "    Yhat = predict_batch(Xb, K_reg, b_reg)\n",
    "    loss = mse(Yhat, Yb)\n",
    "    # gradients: dL/dK = average over batch of 2*(Yhat-Yb)*Xb\n",
    "    diff = 2*(Yhat - Yb) / len(idx)  # (B,1)\n",
    "    # dK shape (s,1,1)\n",
    "    dK = np.tensordot(Xb, diff, axes=([0,2],[0,1]))  # (s,1)\n",
    "    dK = dK.reshape(s,1,1)\n",
    "    db = np.sum(diff, axis=0)  # (1,)\n",
    "    K_reg -= lr*dK\n",
    "    b_reg -= lr*db\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f\"epoch {epoch+1:3d} | loss {loss:.5f}\")\n",
    "\n",
    "# Evaluate on tail\n",
    "X_te, Y_te = make_dataset_1d(x[-300:], s=s)\n",
    "Y_pred = predict_batch(X_te, K_reg, b_reg)\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(range(len(x)), x, label='series', alpha=0.5)\n",
    "base = len(x)-len(Y_pred)\n",
    "plt.plot(range(base+s, base+s+len(Y_pred)), Y_pred[:,0], label='1-step pred')\n",
    "plt.legend(); plt.title(\"Causal CNN (1-layer) one-step forecasts\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d309d160",
   "metadata": {},
   "source": [
    "\n",
    "### Autoregressive generation\n",
    "\n",
    "Given a trained one-step model, we can generate multiple steps by feeding predictions back as inputs.\n",
    "We demonstrate naive AR generation from the last observed window.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8529a528",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ar_generate(x_prefix, steps, K, b):\n",
    "    # x_prefix: last s samples\n",
    "    s = K.shape[0]\n",
    "    buf = list(x_prefix[-s:])\n",
    "    out = []\n",
    "    for _ in range(steps):\n",
    "        Xw = np.array(buf).reshape(1, s, 1)\n",
    "        yhat = predict_batch(Xw, K, b)[0,0]\n",
    "        out.append(yhat)\n",
    "        buf = buf[1:] + [yhat]\n",
    "    return np.array(out)\n",
    "\n",
    "s = K_reg.shape[0]\n",
    "prefix = x[-(s+100):-100]  # last s window from a point before the very end\n",
    "gen = ar_generate(prefix, steps=120, K=K_reg, b=b_reg)\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(range(len(x)), x, label='series', alpha=0.5)\n",
    "start = len(x)-100\n",
    "plt.plot(range(start, start+len(gen)), gen, label='AR gen')\n",
    "plt.legend(); plt.title(\"Autoregressive generation with causal conv regressor\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c15f9f9",
   "metadata": {},
   "source": [
    "\n",
    "## Part 5 — Simple Spectrogram Features (STFT)\n",
    "\n",
    "We simulate an audio waveform and compute a short-time Fourier transform to obtain a spectrogram,\n",
    "then run a tiny CNN across time (treating frequency bins as channels or as the second spatial axis).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda181f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stft_mag(y, win=256, hop=128):\n",
    "    # simple magnitude STFT using NumPy FFT\n",
    "    n = len(y)\n",
    "    windows = []\n",
    "    for start in range(0, n - win + 1, hop):\n",
    "        seg = y[start:start+win] * np.hanning(win)\n",
    "        spec = np.fft.rfft(seg)\n",
    "        windows.append(np.abs(spec))\n",
    "    S = np.stack(windows, axis=0)  # (frames, freq_bins)\n",
    "    return S\n",
    "\n",
    "# fake \"audio\": sum of tones\n",
    "seed_all(8)\n",
    "sr = 8000\n",
    "t = np.linspace(0, 2.0, int(2.0*sr), endpoint=False)\n",
    "y = 0.7*np.sin(2*np.pi*220*t) + 0.4*np.sin(2*np.pi*660*t) + 0.1*np.random.randn(len(t))\n",
    "S = stft_mag(y, win=256, hop=128)  # (frames, freq_bins)\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.imshow(20*np.log10(S.T+1e-6), aspect='auto', origin='lower')\n",
    "plt.title(\"Spectrogram (dB)\"); plt.xlabel(\"frame\"); plt.ylabel(\"freq bin\")\n",
    "plt.colorbar(); plt.show()\n",
    "\n",
    "# Treat as sequence of frames with c = freq_bins channels\n",
    "X_spec = S.astype(np.float32)  # (T, F)\n",
    "# tiny conv along time with kernel size 3, mapping F->Cout\n",
    "T, F = X_spec.shape\n",
    "Cout = 6\n",
    "K_spec = np.random.randn(3, F, Cout) * 0.01\n",
    "H_spec = conv1d_valid(X_spec, K_spec)  # (T-2, Cout)\n",
    "H_spec.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf9d0c",
   "metadata": {},
   "source": [
    "\n",
    "## Part 6 — Padding Variable-Length Sequences\n",
    "\n",
    "Mini-batches need same-length tensors. We pad to the max length in the batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc55c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pad_batch(seqs):\n",
    "    \"\"\"\n",
    "    seqs: list of arrays with shape (t_i, c)\n",
    "    returns X: (B, T_max, c), mask: (B, T_max) where 1 indicates valid.\n",
    "    \"\"\"\n",
    "    B = len(seqs)\n",
    "    c = seqs[0].shape[1]\n",
    "    T_max = max(s.shape[0] for s in seqs)\n",
    "    X = np.zeros((B, T_max, c))\n",
    "    mask = np.zeros((B, T_max), dtype=np.int32)\n",
    "    for i,s in enumerate(seqs):\n",
    "        t = s.shape[0]\n",
    "        X[i, :t, :] = s\n",
    "        mask[i, :t] = 1\n",
    "    return X, mask\n",
    "\n",
    "# demo with three sequences\n",
    "seqs = [np.random.randn(12,2), np.random.randn(7,2), np.random.randn(10,2)]\n",
    "X_pad, mask = pad_batch(seqs)\n",
    "X_pad.shape, mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062ce2b9",
   "metadata": {},
   "source": [
    "\n",
    "## Part 7 — Text Tokenization and Embeddings (NumPy-first)\n",
    "\n",
    "We simulate three tokenization levels and simple embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bae1efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simple_char_tokenize(s):\n",
    "    return list(s)\n",
    "\n",
    "def simple_word_tokenize(s):\n",
    "    return s.lower().split()\n",
    "\n",
    "def build_vocab(tokens_list):\n",
    "    vocab = {}\n",
    "    for tokens in tokens_list:\n",
    "        for tok in tokens:\n",
    "            if tok not in vocab:\n",
    "                vocab[tok] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "def encode(tokens, vocab):\n",
    "    return np.array([vocab[t] for t in tokens], dtype=np.int32)\n",
    "\n",
    "def embedding_lookup(idx, E):\n",
    "    # idx: (n,), E: (V, d)\n",
    "    return E[idx]  # (n, d)\n",
    "\n",
    "# demo\n",
    "texts = [\"Check this out\", \"Check out bowling\", \"this text\"]\n",
    "tok_char = [simple_char_tokenize(s) for s in texts]\n",
    "tok_word = [simple_word_tokenize(s) for s in texts]\n",
    "\n",
    "v_char = build_vocab(tok_char)\n",
    "v_word = build_vocab(tok_word)\n",
    "\n",
    "# build embeddings\n",
    "d_char, d_word = 8, 16\n",
    "E_char = np.random.randn(len(v_char), d_char)*0.1\n",
    "E_word = np.random.randn(len(v_word), d_word)*0.1\n",
    "\n",
    "ex = tok_word[0]\n",
    "ids = encode(ex, v_word)\n",
    "emb = embedding_lookup(ids, E_word)\n",
    "print(\"tokens:\", ex)\n",
    "print(\"ids:\", ids)\n",
    "print(\"embeddings shape:\", emb.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c932f5f",
   "metadata": {},
   "source": [
    "\n",
    "### Tiny text CNN skeleton\n",
    "\n",
    "We will:\n",
    "- tokenize to word ids,\n",
    "- look up embeddings,\n",
    "- apply a small temporal conv and a global average pooling,\n",
    "- classify into two toy classes.\n",
    "\n",
    "This is a non-optimized NumPy sketch for educational purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8d28fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text_to_ids(text, vocab):\n",
    "    return encode(simple_word_tokenize(text), vocab)\n",
    "\n",
    "def global_avg_pool(H):\n",
    "    # H: (T, C) -> (C,)\n",
    "    return H.mean(axis=0)\n",
    "\n",
    "def text_cnn_forward(text, v_word, E_word, K, W_cls, b_cls):\n",
    "    ids = text_to_ids(text, v_word)\n",
    "    X = embedding_lookup(ids, E_word)          # (T, d)\n",
    "    H = conv1d_valid(X, K)                     # (T-s+1, C)\n",
    "    g = global_avg_pool(H)                     # (C,)\n",
    "    logits = W_cls @ g + b_cls                 # (num_classes,)\n",
    "    return logits, {\"ids\":ids, \"H\":H, \"g\":g}\n",
    "\n",
    "# toy data\n",
    "classes = [\"sport\", \"other\"]\n",
    "num_classes = 2\n",
    "s = 3\n",
    "C = 6\n",
    "K = np.random.randn(s, d_word, C)*0.05\n",
    "W_cls = np.random.randn(num_classes, C)*0.05\n",
    "b_cls = np.zeros((num_classes,))\n",
    "\n",
    "text = \"check this bowling\"\n",
    "logits, cache = text_cnn_forward(text, v_word, E_word, K, W_cls, b_cls)\n",
    "logits, logits.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80259b45",
   "metadata": {},
   "source": [
    "\n",
    "## Practice — Your Turn\n",
    "\n",
    "1. **Causal vs non-causal:** Modify `conv1d_valid` to return outputs aligned so each position uses symmetric context.\n",
    "   Then implement a non-causal forecaster and compare information leakage behavior to `conv1d_causal`.\n",
    "\n",
    "2. **Multi-layer dilations:** Chain two dilated layers with dilations $d=1$ and $d=2$. Measure effective receptive field.\n",
    "\n",
    "3. **Spectrogram CNN:** Add one more conv layer on `H_spec` and a small classifier. Try to separate two synthetic audio classes\n",
    "   built from different tone mixtures.\n",
    "\n",
    "4. **Padding masks:** Using `mask` from `pad_batch`, implement a masked global average pooling that ignores padded positions.\n",
    "\n",
    "5. **Embeddings:** Replace the word embeddings with character embeddings and compare the number of tokens, model size,\n",
    "   and performance on a small toy classification set.\n",
    "\n",
    "6. **Autoregressive sampling:** In `ar_generate`, add scheduled sampling: with small probability, use the *true* next value during generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2be078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaac727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5965cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caa00a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253d7656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3cbba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3595a6b",
   "metadata": {},
   "source": [
    "\n",
    "## Summary\n",
    "\n",
    "- 1D convolutions apply naturally to sequences and can be made **causal**.\n",
    "- **Dilations** expand receptive field exponentially with depth.\n",
    "- Forecasting uses causal models to avoid information leakage; AR generation reuses model outputs.\n",
    "- Audio tasks often use **spectrograms** as inputs; text requires **tokenization** and **embeddings**.\n",
    "- Variable-length sequences need **padding** and masking for mini-batches.\n",
    "\n",
    "Extend any section with deeper experiments.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
